# Nynet Engine Package Configuration

name = "Nynet"
version = "1.0.0"
description = "Nyx Neural Network Architecture Engine - layers, attention, RNN, transformers"
author = "Nyx Team"
author_email = "team@nyxlang.dev"
license = "MIT"
homepage = "https://github.com/nyxlang/Nynet"

keywords = ["nyx", "neural-network", "layers", "attention", "transformer", "rnn", "lstm", "cnn"]

dependencies = ["nyx >= 2.0.0"]

[scripts]
Nynet = "nynet:create_net"

[modules]
activations = "ReLU, GELU, Sigmoid, Tanh, Softmax"
attention = "Multi-head attention and transformer blocks"
containers = "Sequential and ResidualBlock"
embedding = "Embedding and positional encoding"
layers = "Linear, Conv2d, BatchNorm, LayerNorm layers"
pooling = "MaxPool, AvgPool, AdaptivePool"
recurrent = "RNN, LSTM, GRU layers"

[platform]
any = true

[capabilities]
convolutional = "2D convolution with padding and stride"
normalization = "Batch and layer normalization"
recurrent_networks = "RNN/LSTM/GRU with bidirectional support"
residual_connections = "Skip connection residual blocks"
transformer_blocks = "Multi-head attention transformer layers"

